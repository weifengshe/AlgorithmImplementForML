# graph the reinforcement learning for easy grid world
library(ggplot2)
library(reshape)
Iterations <- seq(1, 100)

## graph the steps
ValueIteration <- c(941,123,170,27,12,9,13,10,19,10,12,17,16,14,20,13,12,10,9,11,9,11,10,12,10,9,11,12,12,9,13,19,9,12,11,17,13,9,13,11,10,18,13,9,11,16,9,13,11,11,11,10,14,9,11,17,11,10,10,12,12,9,9,12,9,13,11,17,14,10,9,14,9,14,12,12,11,9,12,15,10,12,10,13,14,13,11,11,12,16,13,11,11,11,16,21,12,11,9,10)
range(ValueIteration) # 9, 941
PolicyIteration <- c(1409,1059,154,14,15,15,11,10,12,9,9,10,11,11,10,11,9,18,11,13,10,11,18,24,19,12,12,13,13,11,16,12,10,12,18,17,14,10,20,14,9,9,14,11,11,11,12,13,11,12,11,13,9,9,9,10,10,14,11,11,12,14,13,12,10,10,11,12,9,9,11,12,9,10,10,11,10,9,12,10,10,11,13,16,12,13,12,9,9,9,12,9,10,12,11,13,9,9,11,11)
range(PolicyIteration) # 9, 1409
QLearning <- c(63,50,61,109,56,20,14,17,22,20,15,67,9,11,11,18,9,13,25,11,22,10,15,12,11,10,10,15,10,12,10,10,16,12,11,13,55,13,9,14,11,13,36,17,15,14,24,17,21,27,24,11,17,23,17,32,32,13,24,10,11,20,15,12,12,14,11,13,27,10,28,19,9,15,16,16,10,56,28,17,28,10,13,36,12,40,16,15,23,17,9,17,13,12,9,13,14,10,12,13)
range(QLearning) # 9, 109

steps <- cbind(Iterations, ValueIteration, PolicyIteration, QLearning) 
steps <- as.matrix(steps)

rownames(steps) <- steps[,'Iterations']
steps <- subset(steps, select = -c(Iterations))
steps <- melt(steps, id.vars = 'Iterations', variable.names = 'algo')
colnames(steps) <- c('Iterations', 'algo', 'steps')

head(steps)
tail(steps)

ggplot(steps, aes(Iterations, steps)) + 
        geom_line(aes(colour = algo)) + 
        ggtitle("Steps for easy grid world") + ylim(0, 200)

# graph the times
ValueIteration <- c(103,3,2,4,4,5,5,9,5,6,7,6,12,6,8,12,10,14,14,40,11,13,17,14,37,15,19,10,14,175,18,160,45,29,14,15,16,15,17,35,18,19,16,20,18,16,12,15,23,25,21,88,54,43,25,21,86,23,19,16,15,15,18,16,16,18,15,18,60,24,15,17,24,28,59,92,52,40,20,18,16,17,45,27,23,21,24,21,17,16,16,18,17,40,37,22,24,18,19,75)
range(ValueIteration) # 2 , 175
PolicyIteration <- c(14,4,6,6,69,11,12,18,14,16,17,40,14,14,16,46,19,17,16,17,18,18,24,19,17,13,14,50,81,57,33,18,13,44,25,26,16,21,14,17,17,18,17,25,75,32,22,21,23,21,19,19,30,99,26,33,22,24,28,28,36,29,25,26,29,27,28,28,35,27,29,42,39,34,31,65,75,121,75,41,35,40,32,54,64,47,42,44,63,59,47,44,39,78,64,56,45,107,58,44)
range(PolicyIteration) # 4, 121
QLearning <- c(151,8,8,25,4,4,25,24,4,8,8,6,23,6,78,4,3,5,4,4,3,5,5,5,6,5,9,6,4,5,6,7,6,7,8,4,9,4,3,4,21,6,9,30,7,6,6,6,7,6,7,8,9,4,6,5,7,6,8,6,7,6,8,6,5,5,7,7,7,5,5,6,7,6,7,6,6,6,9,6,6,6,8,8,5,6,10,7,7,8,9,15,10,16,10,8,7,6,6,7)
range(QLearning) # 3, 151

times <- cbind(Iterations, ValueIteration, PolicyIteration, QLearning)
times <- as.matrix(times)

rownames(times) <- times[,'Iterations']
times <- subset(times, select = -c(Iterations))
times <- melt(times, id.vars = 'Iterations', variable.names = 'algo')
colnames(times) <- c('Iterations', 'algo', 'miniseconds')

head(times)
tail(times)

ggplot(times, aes(Iterations, miniseconds)) + 
        geom_line(aes(colour = algo)) + 
        ggtitle("Miniseconds required for eash grid world")





# graph the rewards
ValueIteration <- c(-839.0,-21.0,-68.0,75.0,90.0,93.0,89.0,92.0,83.0,92.0,90.0,85.0,86.0,88.0,82.0,89.0,90.0,92.0,93.0,91.0,93.0,91.0,92.0,90.0,92.0,93.0,91.0,90.0,90.0,93.0,89.0,83.0,93.0,90.0,91.0,85.0,89.0,93.0,89.0,91.0,92.0,84.0,89.0,93.0,91.0,86.0,93.0,89.0,91.0,91.0,91.0,92.0,88.0,93.0,91.0,85.0,91.0,92.0,92.0,90.0,90.0,93.0,93.0,90.0,93.0,89.0,91.0,85.0,88.0,92.0,93.0,88.0,93.0,88.0,90.0,90.0,91.0,93.0,90.0,87.0,92.0,90.0,92.0,89.0,88.0,89.0,91.0,91.0,90.0,86.0,89.0,91.0,91.0,91.0,86.0,81.0,90.0,91.0,93.0,92.0)
range(ValueIteration) # -839 93
PolicyIteration <- c(-1307.0,-957.0,-52.0,88.0,87.0,87.0,91.0,92.0,90.0,93.0,93.0,92.0,91.0,91.0,92.0,91.0,93.0,84.0,91.0,89.0,92.0,91.0,84.0,78.0,83.0,90.0,90.0,89.0,89.0,91.0,86.0,90.0,92.0,90.0,84.0,85.0,88.0,92.0,82.0,88.0,93.0,93.0,88.0,91.0,91.0,91.0,90.0,89.0,91.0,90.0,91.0,89.0,93.0,93.0,93.0,92.0,92.0,88.0,91.0,91.0,90.0,88.0,89.0,90.0,92.0,92.0,91.0,90.0,93.0,93.0,91.0,90.0,93.0,92.0,92.0,91.0,92.0,93.0,90.0,92.0,92.0,91.0,89.0,86.0,90.0,89.0,90.0,93.0,93.0,93.0,90.0,93.0,92.0,90.0,91.0,89.0,93.0,93.0,91.0,91.0)
range(PolicyIteration) #-1307 93
QLearning <- c(39.0,52.0,41.0,-7.0,46.0,82.0,88.0,85.0,80.0,82.0,87.0,35.0,93.0,91.0,91.0,84.0,93.0,89.0,77.0,91.0,80.0,92.0,87.0,90.0,91.0,92.0,92.0,87.0,92.0,90.0,92.0,92.0,86.0,90.0,91.0,89.0,47.0,89.0,93.0,88.0,91.0,89.0,66.0,85.0,87.0,88.0,78.0,85.0,81.0,75.0,78.0,91.0,85.0,79.0,85.0,70.0,70.0,89.0,78.0,92.0,91.0,82.0,87.0,90.0,90.0,88.0,91.0,89.0,75.0,92.0,74.0,83.0,93.0,87.0,86.0,86.0,92.0,46.0,74.0,85.0,74.0,92.0,89.0,66.0,90.0,62.0,86.0,87.0,79.0,85.0,93.0,85.0,89.0,90.0,93.0,89.0,88.0,92.0,90.0,89.0)
range((QLearning)) #-7 93
rewards <- cbind(Iterations, ValueIteration, PolicyIteration, QLearning)

rewards <- as.matrix(rewards)
rownames(rewards) <- rewards[,'Iterations']
rewards <- subset(rewards, select = -c(Iterations))
rewards <- melt(rewards, id.vars = 'Iterations', variable.names = 'algo')
colnames(rewards) <- c('Iterations', 'algo', 'rewards')
range(rewards$rewards)

head(rewards)
tail(rewards)

ggplot(rewards, aes(Iterations, rewards)) + 
        geom_line(aes(colour = algo)) + 
        ggtitle("Rewards for eash grid world") + ylim(-100, 100)

